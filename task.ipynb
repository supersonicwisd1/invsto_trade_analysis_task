{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41bce18d",
   "metadata": {},
   "source": [
    "## Connecting to the the Postgres DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1dfbbe71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(postgresql://user:***@localhost:5432/trade_stat)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def conn_to_db():\n",
    "    username = os.getenv('DB_USERNAME')\n",
    "    password = os.getenv('DB_PASSWORD')\n",
    "    host = os.getenv('HOST')\n",
    "    port = os.getenv('PORT')\n",
    "    database = os.getenv('DATABASE')\n",
    "\n",
    "    try:\n",
    "        engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{database}')\n",
    "    except Exception as e:\n",
    "        print(f'Error: Could not connect to the database.\\n Reason:{e}')\n",
    "\n",
    "    return engine\n",
    "conn_to_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670976a6",
   "metadata": {},
   "source": [
    "## Insert Data into the stock_data table create in the DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "625ef83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def insert_data():\n",
    "    # Load the data from CSV\n",
    "    file_path = 'HINDALCO.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Insert data into the database\n",
    "    df.to_sql('stock_data', conn_to_db(), if_exists='replace', index=False)\n",
    "\n",
    "# insert_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d30b3cf",
   "metadata": {},
   "source": [
    "## EXPLORATION OF DATA\n",
    "#### Reading data form the DataBase\n",
    "#### Checking the quality of data via check_data_quality function\n",
    "#### Calculation of the moving average crossover strategy via moving_average_crossover_strategy function\n",
    "\n",
    "##### additions\n",
    "#### Calculation of drawdown \n",
    "#### Calculation of the performance using sharpe ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94d7b948",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Open column is not float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstrument\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstrument column should be an object type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatatime column should be an object type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 21\u001b[0m check_data_quality(df)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Sample of the data\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[0;32mIn[48], line 14\u001b[0m, in \u001b[0;36mcheck_data_quality\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m     12\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfillna(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffill\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpen column is not float64\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh column is not float64\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose column should be a float64\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Open column is not float64"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "table_name = os.getenv('TABLE_NAME')\n",
    "query = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "# Load data into a Pandas DataFrame\n",
    "df = pd.read_sql(query, conn_to_db())\n",
    "\n",
    "def check_data_quality(df):\n",
    "    if df.isnull().values.any():\n",
    "        df = df.fillna(method='ffill')  \n",
    "\n",
    "    assert df['open'].dtype == np.float64, \"Open column is not float64\"\n",
    "    assert df['high'].dtype == np.float64, \"High column is not float64\"\n",
    "    assert df['close'].dtype == np.float64, \"Close column should be a float64\"\n",
    "    assert df['volume'].dtype == np.int64, \"Volume column should be a int64\"\n",
    "    assert df['instrument'].dtype == object, \"Instrument column should be an object type\"\n",
    "    assert df['datetime'].dtype == object, \"Datatime column should be an object type\"\n",
    "\n",
    "check_data_quality(df)\n",
    "\n",
    "# Sample of the data\n",
    "print(df.head())\n",
    "\n",
    "def moving_average_crossover_strategy(df):\n",
    "    short_window = 40\n",
    "    long_window = 100\n",
    "\n",
    "    # Calculate moving averages\n",
    "    df['short_mavg'] = df['close'].rolling(window=short_window, min_periods=1).mean()\n",
    "    df['long_mavg'] = df['close'].rolling(window=long_window, min_periods=1).mean()\n",
    "\n",
    "    # Generating signals\n",
    "    df['signal'] = 0\n",
    "    df.loc[short_window:, 'signal'] = np.where(df['short_mavg'][short_window:] > df['long_mavg'][short_window:], 1, 0)\n",
    "    df['positions'] = df['signal'].diff()\n",
    "\n",
    "    return df\n",
    "\n",
    "result_df = moving_average_crossover_strategy(df)\n",
    "\n",
    "# calculating strategy return \n",
    "def calculate_returns(df):\n",
    "    df['returns'] = df['close'].pct_change()\n",
    "    df['strategy_returns'] = df['returns'] * df['positions'].shift(1)\n",
    "    return df\n",
    "\n",
    "result_df = calculate_returns(result_df)\n",
    "\n",
    "# Calculate cumulative returns\n",
    "result_df['cumulative_returns'] = (1 + result_df['strategy_returns']).cumprod()\n",
    "\n",
    "def calculate_drawdown(df):\n",
    "    # Calculate the cumulative maximum value to track the peak\n",
    "    df['cumulative_max'] = df['cumulative_returns'].cummax()\n",
    "    # Calculate drawdown\n",
    "    df['drawdown'] = df['cumulative_max'] - df['cumulative_returns']\n",
    "    return df\n",
    "\n",
    "result_df = calculate_drawdown(result_df)\n",
    "\n",
    "\n",
    "def calculate_performance_metrics(df):\n",
    "    #Assuming a risk-free rate of 0 for simplicity\n",
    "    sharpe_ratio = df['strategy_returns'].mean() / df['strategy_returns'].std() * np.sqrt(252)\n",
    "\n",
    "    # Max Drawdown\n",
    "    max_drawdown = df['drawdown'].max()\n",
    "\n",
    "    return sharpe_ratio, max_drawdown\n",
    "\n",
    "sharpe_ratio, max_drawdown = calculate_performance_metrics(result_df)\n",
    "\n",
    "# Output results\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio}\")\n",
    "print(f\"Maximum Drawdown: {max_drawdown}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6510f9c",
   "metadata": {},
   "source": [
    "## Visualization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccaa81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Cumulative Returns\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(result_df.index, result_df['cumulative_returns'], label='Cumulative Returns')\n",
    "plt.title('Cumulative Returns Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualization of Drawdown\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.fill_between(result_df.index, result_df['drawdown'], color='red', label='Drawdown')\n",
    "plt.title('Drawdown Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Drawdown')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6537f455",
   "metadata": {},
   "source": [
    "## Run a Test using unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ad072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import datetime\n",
    "\n",
    "class TestStockData(unittest.TestCase):\n",
    "    def test_data_types(self):\n",
    "        data = [\n",
    "            (\"2014-01-24 00:00:00\", 114.00, 115.35, 113.00, 113.15, 5737135, \"HINDALCO\"),\n",
    "            (\"2014-01-27 00:00:00\", 111.10, 112.70, 109.30, 112.00, 8724577, \"HINDALCO\"),\n",
    "            (\"2014-01-28 00:00:00\", 113.80, 115.00, 109.75, 110.00, 4513345, \"HINDALCO\"),\n",
    "            (\"2014-01-29 00:00:00\", 111.75, 114.75, 111.15, 114.50, 4713458, \"HINDALCO\"),\n",
    "            (\"2014-01-30 00:00:00\", 108.10, 110.70, 107.60, 110.20, 5077231, \"HINDALCO\"),\n",
    "            ]\n",
    "\n",
    "        for record in data:\n",
    "            date_object = datetime.datetime.strptime(record[0], '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            self.assertIsInstance(date_object, datetime.datetime)\n",
    "            self.assertIsInstance(record[1], float)\n",
    "            self.assertIsInstance(record[2], float)\n",
    "            self.assertIsInstance(record[3], float)\n",
    "            self.assertIsInstance(record[4], float)\n",
    "            self.assertIsInstance(record[5], int)\n",
    "            self.assertIsInstance(record[6], str)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=[''], exit=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
